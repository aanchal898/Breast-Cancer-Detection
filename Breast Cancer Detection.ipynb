{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#train set\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, #behaves like feature scaling\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "        target_size=(50, 50),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "        target_size=(50, 50),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n",
      "Found 55504 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From <ipython-input-7-3cece67bab77>:56: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "4910/4909 [==============================] - 1702s 347ms/step - loss: 0.4342 - accuracy: 0.8068 - val_loss: 0.5954 - val_accuracy: 0.6984\n",
      "Epoch 2/15\n",
      "4910/4909 [==============================] - 2938s 598ms/step - loss: 0.3822 - accuracy: 0.8358 - val_loss: 0.4097 - val_accuracy: 0.8051\n",
      "Epoch 3/15\n",
      "4910/4909 [==============================] - 1754s 357ms/step - loss: 0.3717 - accuracy: 0.8406 - val_loss: 0.6150 - val_accuracy: 0.6896\n",
      "Epoch 4/15\n",
      "4910/4909 [==============================] - 1387s 282ms/step - loss: 0.3658 - accuracy: 0.8446 - val_loss: 0.3804 - val_accuracy: 0.8363\n",
      "Epoch 5/15\n",
      "4910/4909 [==============================] - 1196s 244ms/step - loss: 0.3600 - accuracy: 0.8471 - val_loss: 0.4145 - val_accuracy: 0.8164\n",
      "Epoch 6/15\n",
      "4910/4909 [==============================] - 1469s 299ms/step - loss: 0.3627 - accuracy: 0.8458 - val_loss: 0.4053 - val_accuracy: 0.8146\n",
      "Epoch 7/15\n",
      "4910/4909 [==============================] - 993s 202ms/step - loss: 0.3590 - accuracy: 0.8472 - val_loss: 0.4687 - val_accuracy: 0.7909\n",
      "Epoch 8/15\n",
      "4910/4909 [==============================] - 985s 201ms/step - loss: 0.3553 - accuracy: 0.8490 - val_loss: 0.5099 - val_accuracy: 0.7539\n",
      "Epoch 9/15\n",
      "4910/4909 [==============================] - 1087s 221ms/step - loss: 0.3540 - accuracy: 0.8495 - val_loss: 0.4042 - val_accuracy: 0.8286\n",
      "Epoch 10/15\n",
      "4910/4909 [==============================] - 1000s 204ms/step - loss: 0.3513 - accuracy: 0.8511 - val_loss: 0.4201 - val_accuracy: 0.8120\n",
      "Epoch 11/15\n",
      "4910/4909 [==============================] - 1042s 212ms/step - loss: 0.3478 - accuracy: 0.8527 - val_loss: 0.4418 - val_accuracy: 0.7975\n",
      "Epoch 12/15\n",
      "4910/4909 [==============================] - 1107s 225ms/step - loss: 0.3459 - accuracy: 0.8539 - val_loss: 0.3857 - val_accuracy: 0.8274\n",
      "Epoch 13/15\n",
      "4910/4909 [==============================] - 860s 175ms/step - loss: 0.3457 - accuracy: 0.8542 - val_loss: 0.3749 - val_accuracy: 0.8316\n",
      "Epoch 14/15\n",
      "4910/4909 [==============================] - 621s 127ms/step - loss: 0.3421 - accuracy: 0.8552 - val_loss: 0.4007 - val_accuracy: 0.8187\n",
      "Epoch 15/15\n",
      "4910/4909 [==============================] - 588s 120ms/step - loss: 0.3421 - accuracy: 0.8558 - val_loss: 0.3959 - val_accuracy: 0.8261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25409763848>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequencing 1 simple\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "#1st Conv layer\n",
    "classifier.add(Convolution2D(64, (9, 9), input_shape=(50, 50, 3),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(4,4)))\n",
    "#2nd Conv layer\n",
    "classifier.add(Convolution2D(32, (3, 3), strides=(1,1),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "                                                 target_size = (50, 50),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "                                            target_size = (50, 50),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "#steps_per_epoch = number of images in training set / batch size \n",
    "#validation_steps = number of images in test set / batch size \n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=(47858+109248)/32,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=(15756+39748)/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n",
      "Found 55504 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "4910/4909 [==============================] - 771s 157ms/step - loss: 0.4102 - accuracy: 0.8241 - val_loss: 0.5365 - val_accuracy: 0.7693\n",
      "Epoch 2/15\n",
      "4910/4909 [==============================] - 831s 169ms/step - loss: 0.3934 - accuracy: 0.8303 - val_loss: 1.1658 - val_accuracy: 0.7077\n",
      "Epoch 3/15\n",
      "4910/4909 [==============================] - 909s 185ms/step - loss: 0.3805 - accuracy: 0.8362 - val_loss: 0.7421 - val_accuracy: 0.7898\n",
      "Epoch 4/15\n",
      "4910/4909 [==============================] - 899s 183ms/step - loss: 0.3725 - accuracy: 0.8397 - val_loss: 0.4731 - val_accuracy: 0.7902\n",
      "Epoch 5/15\n",
      "4910/4909 [==============================] - 808s 165ms/step - loss: 0.3655 - accuracy: 0.8431 - val_loss: 0.4209 - val_accuracy: 0.8035\n",
      "Epoch 6/15\n",
      "4910/4909 [==============================] - 869s 177ms/step - loss: 0.3598 - accuracy: 0.8458 - val_loss: 0.7557 - val_accuracy: 0.7392\n",
      "Epoch 7/15\n",
      "4910/4909 [==============================] - 796s 162ms/step - loss: 0.3551 - accuracy: 0.8489 - val_loss: 0.5688 - val_accuracy: 0.7824\n",
      "Epoch 8/15\n",
      "4910/4909 [==============================] - 643s 131ms/step - loss: 0.3528 - accuracy: 0.8490 - val_loss: 0.4214 - val_accuracy: 0.8121\n",
      "Epoch 9/15\n",
      "4910/4909 [==============================] - 606s 123ms/step - loss: 0.3501 - accuracy: 0.8513 - val_loss: 1.0800 - val_accuracy: 0.7044\n",
      "Epoch 10/15\n",
      "4910/4909 [==============================] - 614s 125ms/step - loss: 0.3478 - accuracy: 0.8523 - val_loss: 0.4818 - val_accuracy: 0.7928\n",
      "Epoch 11/15\n",
      "4910/4909 [==============================] - 626s 127ms/step - loss: 0.3457 - accuracy: 0.8538 - val_loss: 0.6840 - val_accuracy: 0.7405\n",
      "Epoch 12/15\n",
      "4910/4909 [==============================] - 637s 130ms/step - loss: 0.3434 - accuracy: 0.8552 - val_loss: 0.7367 - val_accuracy: 0.7387\n",
      "Epoch 13/15\n",
      "4910/4909 [==============================] - 642s 131ms/step - loss: 0.3416 - accuracy: 0.8559 - val_loss: 1.3659 - val_accuracy: 0.7434\n",
      "Epoch 14/15\n",
      "4910/4909 [==============================] - 657s 134ms/step - loss: 0.3407 - accuracy: 0.8564 - val_loss: 2.1010 - val_accuracy: 0.5951\n",
      "Epoch 15/15\n",
      "4910/4909 [==============================] - 642s 131ms/step - loss: 0.3391 - accuracy: 0.8572 - val_loss: 1.2665 - val_accuracy: 0.7177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b71afe548>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequencing 4 simple+BN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "classifier = Sequential()\n",
    "#1st Conv layer\n",
    "classifier.add(Convolution2D(64, (9, 9), input_shape=(50, 50, 3),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(4,4)))\n",
    "#2nd Conv layer\n",
    "classifier.add(Convolution2D(32, (3, 3),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "                                                 target_size = (50, 50),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "                                            target_size = (50, 50),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "#steps_per_epoch = number of images in training set / batch size \n",
    "#validation_steps = number of images in test set / batch size \n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=(47858+109248)/32,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=(15756+39748)/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4910\n",
      "1735\n"
     ]
    }
   ],
   "source": [
    "print(len(training_set));\n",
    "print(len(test_set));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n",
      "Found 55504 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "4910/4909 [==============================] - 551s 112ms/step - loss: 0.4250 - accuracy: 0.8188 - val_loss: 1.9554 - val_accuracy: 0.7160\n",
      "Epoch 2/15\n",
      "4910/4909 [==============================] - 986s 201ms/step - loss: 0.3937 - accuracy: 0.8318 - val_loss: 0.8438 - val_accuracy: 0.7545\n",
      "Epoch 3/15\n",
      "4910/4909 [==============================] - 994s 202ms/step - loss: 0.3791 - accuracy: 0.8370 - val_loss: 1.8210 - val_accuracy: 0.7251\n",
      "Epoch 4/15\n",
      "4910/4909 [==============================] - 977s 199ms/step - loss: 0.3750 - accuracy: 0.8376 - val_loss: 0.5195 - val_accuracy: 0.7617\n",
      "Epoch 5/15\n",
      "4910/4909 [==============================] - 878s 179ms/step - loss: 0.3698 - accuracy: 0.8403 - val_loss: 0.6458 - val_accuracy: 0.7639\n",
      "Epoch 6/15\n",
      "4910/4909 [==============================] - 800s 163ms/step - loss: 0.3659 - accuracy: 0.8425 - val_loss: 0.6050 - val_accuracy: 0.8044\n",
      "Epoch 7/15\n",
      "4910/4909 [==============================] - 759s 155ms/step - loss: 0.3623 - accuracy: 0.8445 - val_loss: 0.4649 - val_accuracy: 0.7840\n",
      "Epoch 8/15\n",
      "4910/4909 [==============================] - 759s 155ms/step - loss: 0.3607 - accuracy: 0.8450 - val_loss: 0.7802 - val_accuracy: 0.7167\n",
      "Epoch 9/15\n",
      "4910/4909 [==============================] - 758s 154ms/step - loss: 0.3594 - accuracy: 0.8463 - val_loss: 0.7961 - val_accuracy: 0.5605\n",
      "Epoch 10/15\n",
      "4910/4909 [==============================] - 580s 118ms/step - loss: 0.3572 - accuracy: 0.8472 - val_loss: 0.8959 - val_accuracy: 0.5663\n",
      "Epoch 11/15\n",
      "4910/4909 [==============================] - 567s 115ms/step - loss: 0.3603 - accuracy: 0.8446 - val_loss: 1.8324 - val_accuracy: 0.7202\n",
      "Epoch 12/15\n",
      "4910/4909 [==============================] - 491s 100ms/step - loss: 0.3560 - accuracy: 0.8482 - val_loss: 0.9503 - val_accuracy: 0.4616\n",
      "Epoch 13/15\n",
      "4910/4909 [==============================] - 689s 140ms/step - loss: 0.3541 - accuracy: 0.8485 - val_loss: 0.8646 - val_accuracy: 0.7220\n",
      "Epoch 14/15\n",
      "4910/4909 [==============================] - 696s 142ms/step - loss: 0.3554 - accuracy: 0.8486 - val_loss: 0.6469 - val_accuracy: 0.7755\n",
      "Epoch 15/15\n",
      "4910/4909 [==============================] - 629s 128ms/step - loss: 0.3543 - accuracy: 0.8493 - val_loss: 0.4650 - val_accuracy: 0.7729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b79336f88>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequencing 3 simple+BN+Dropout\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "classifier = Sequential()\n",
    "#1st Conv layer\n",
    "classifier.add(Convolution2D(64, (9, 9), input_shape=(50, 50, 3),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(4,4)))\n",
    "#2nd Conv layer\n",
    "classifier.add(Convolution2D(32, (3, 3),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "                                                 target_size = (50, 50),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "                                            target_size = (50, 50),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "#steps_per_epoch = number of images in training set / batch size (which is 55839/32)\n",
    "#validation_steps = number of images in test set / batch size (which is 18739/32)\n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=(47858+109248)/32,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=(15756+39748)/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n",
      "Found 55504 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "4910/4909 [==============================] - 682s 139ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 2/15\n",
      "4910/4909 [==============================] - 587s 120ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 3/15\n",
      "4910/4909 [==============================] - 32255s 7s/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 4/15\n",
      "4910/4909 [==============================] - 2164s 441ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 5/15\n",
      "4910/4909 [==============================] - 1576s 321ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 6/15\n",
      "4910/4909 [==============================] - 1927s 393ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 7/15\n",
      "4910/4909 [==============================] - 986s 201ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 8/15\n",
      "4910/4909 [==============================] - 630s 128ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 9/15\n",
      "4910/4909 [==============================] - 627s 128ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 10/15\n",
      "4910/4909 [==============================] - 656s 134ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 11/15\n",
      "4910/4909 [==============================] - 588s 120ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 12/15\n",
      "4910/4909 [==============================] - 562s 115ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 13/15\n",
      "4910/4909 [==============================] - 566s 115ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 14/15\n",
      "4910/4909 [==============================] - 570s 116ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n",
      "Epoch 15/15\n",
      "4910/4909 [==============================] - 1292s 263ms/step - loss: 4.6454 - accuracy: 0.6954 - val_loss: 4.3289 - val_accuracy: 0.7161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b02d89188>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequencing 5 simple+Dropout\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "classifier = Sequential()\n",
    "#1st Conv layer\n",
    "classifier.add(Convolution2D(64, (9, 9), input_shape=(50, 50, 3),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(4,4)))\n",
    "#2nd Conv layer\n",
    "classifier.add(Convolution2D(32, (3, 3),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 1, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "                                                 target_size = (50, 50),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "                                            target_size = (50, 50),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "#steps_per_epoch = number of images in training set / batch size (which is 55839/32)\n",
    "#validation_steps = number of images in test set / batch size (which is 18739/32)\n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=(47858+109248)/32,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=(15756+39748)/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n",
      "Found 55504 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "4910/4909 [==============================] - 900s 183ms/step - loss: 0.4487 - accuracy: 0.7990 - val_loss: 0.4995 - val_accuracy: 0.7665\n",
      "Epoch 2/15\n",
      "4910/4909 [==============================] - 1022s 208ms/step - loss: 0.4140 - accuracy: 0.8187 - val_loss: 0.3902 - val_accuracy: 0.8308\n",
      "Epoch 3/15\n",
      "4910/4909 [==============================] - 898s 183ms/step - loss: 0.4035 - accuracy: 0.8236 - val_loss: 0.4449 - val_accuracy: 0.8111\n",
      "Epoch 4/15\n",
      "4910/4909 [==============================] - 878s 179ms/step - loss: 0.3975 - accuracy: 0.8276 - val_loss: 0.4909 - val_accuracy: 0.7721\n",
      "Epoch 5/15\n",
      "4910/4909 [==============================] - 814s 166ms/step - loss: 0.3930 - accuracy: 0.8296 - val_loss: 0.4392 - val_accuracy: 0.8043\n",
      "Epoch 6/15\n",
      "4910/4909 [==============================] - 857s 175ms/step - loss: 0.3865 - accuracy: 0.8330 - val_loss: 0.4537 - val_accuracy: 0.7910\n",
      "Epoch 7/15\n",
      "4910/4909 [==============================] - 891s 182ms/step - loss: 0.3833 - accuracy: 0.8341 - val_loss: 0.4187 - val_accuracy: 0.8209\n",
      "Epoch 8/15\n",
      "4910/4909 [==============================] - 884s 180ms/step - loss: 0.3794 - accuracy: 0.8368 - val_loss: 0.4977 - val_accuracy: 0.7713\n",
      "Epoch 9/15\n",
      "4910/4909 [==============================] - 879s 179ms/step - loss: 0.3748 - accuracy: 0.8387 - val_loss: 0.4700 - val_accuracy: 0.7892\n",
      "Epoch 10/15\n",
      "4910/4909 [==============================] - 857s 175ms/step - loss: 0.3737 - accuracy: 0.8390 - val_loss: 0.4121 - val_accuracy: 0.8229\n",
      "Epoch 11/15\n",
      "4910/4909 [==============================] - 844s 172ms/step - loss: 0.3710 - accuracy: 0.8409 - val_loss: 0.3867 - val_accuracy: 0.8377\n",
      "Epoch 12/15\n",
      "4910/4909 [==============================] - 871s 177ms/step - loss: 0.3685 - accuracy: 0.8423 - val_loss: 0.4358 - val_accuracy: 0.8041\n",
      "Epoch 13/15\n",
      "4910/4909 [==============================] - 785s 160ms/step - loss: 0.3666 - accuracy: 0.8429 - val_loss: 0.4172 - val_accuracy: 0.8155\n",
      "Epoch 14/15\n",
      "4910/4909 [==============================] - 699s 142ms/step - loss: 0.3637 - accuracy: 0.8443 - val_loss: 0.4042 - val_accuracy: 0.8241\n",
      "Epoch 15/15\n",
      "4910/4909 [==============================] - 694s 141ms/step - loss: 0.3630 - accuracy: 0.8448 - val_loss: 0.4002 - val_accuracy: 0.8283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b0b341288>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequencing 6 simple+annlayers=2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "#1st Conv layer\n",
    "classifier.add(Convolution2D(64, (9, 9), input_shape=(50, 50, 3),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(4,4)))\n",
    "#2nd Conv layer\n",
    "classifier.add(Convolution2D(32, (3, 3),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid')) #two ann layers only\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "                                                 target_size = (50, 50),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "                                            target_size = (50, 50),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "#steps_per_epoch = number of images in training set / batch size (which is 55839/32)\n",
    "#validation_steps = number of images in test set / batch size (which is 18739/32)\n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=(47858+109248)/32,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=(15756+39748)/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n",
      "Found 55504 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "4910/4909 [==============================] - 1279s 261ms/step - loss: 0.4094 - accuracy: 0.8247 - val_loss: 0.6643 - val_accuracy: 0.7578\n",
      "Epoch 2/15\n",
      "4910/4909 [==============================] - 1296s 264ms/step - loss: 0.3769 - accuracy: 0.8393 - val_loss: 0.4140 - val_accuracy: 0.8158\n",
      "Epoch 3/15\n",
      "4910/4909 [==============================] - 1002s 204ms/step - loss: 0.3663 - accuracy: 0.8427 - val_loss: 0.7772 - val_accuracy: 0.7184\n",
      "Epoch 4/15\n",
      "4910/4909 [==============================] - 927s 189ms/step - loss: 0.3596 - accuracy: 0.8460 - val_loss: 0.5190 - val_accuracy: 0.7786\n",
      "Epoch 5/15\n",
      "4910/4909 [==============================] - 920s 187ms/step - loss: 0.3561 - accuracy: 0.8475 - val_loss: 0.7034 - val_accuracy: 0.7250\n",
      "Epoch 6/15\n",
      "4910/4909 [==============================] - 894s 182ms/step - loss: 0.3522 - accuracy: 0.8503 - val_loss: 1.1064 - val_accuracy: 0.7619\n",
      "Epoch 7/15\n",
      "4910/4909 [==============================] - 880s 179ms/step - loss: 0.3527 - accuracy: 0.8494 - val_loss: 0.5871 - val_accuracy: 0.7448\n",
      "Epoch 8/15\n",
      "4910/4909 [==============================] - 883s 180ms/step - loss: 0.3518 - accuracy: 0.8499 - val_loss: 1.5877 - val_accuracy: 0.7379\n",
      "Epoch 9/15\n",
      "4910/4909 [==============================] - 1069s 218ms/step - loss: 0.3494 - accuracy: 0.8522 - val_loss: 1.0210 - val_accuracy: 0.4899\n",
      "Epoch 10/15\n",
      "4910/4909 [==============================] - 1785s 363ms/step - loss: 0.3498 - accuracy: 0.8516 - val_loss: 0.6456 - val_accuracy: 0.7832\n",
      "Epoch 11/15\n",
      "4910/4909 [==============================] - 1895s 386ms/step - loss: 0.3571 - accuracy: 0.8468 - val_loss: 1.0326 - val_accuracy: 0.7023\n",
      "Epoch 12/15\n",
      "4910/4909 [==============================] - 1978s 403ms/step - loss: 0.3543 - accuracy: 0.8483 - val_loss: 0.9721 - val_accuracy: 0.7488\n",
      "Epoch 13/15\n",
      "4910/4909 [==============================] - 1929s 393ms/step - loss: 0.3556 - accuracy: 0.8483 - val_loss: 1.1601 - val_accuracy: 0.6619\n",
      "Epoch 14/15\n",
      "4910/4909 [==============================] - 1474s 300ms/step - loss: 0.3555 - accuracy: 0.8486 - val_loss: 1.0185 - val_accuracy: 0.5256\n",
      "Epoch 15/15\n",
      "4910/4909 [==============================] - 696s 142ms/step - loss: 0.3540 - accuracy: 0.8494 - val_loss: 1.2790 - val_accuracy: 0.7508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b129e42c8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequencing 7 simple+annlayers3+BN+DO\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "#1st Conv layer\n",
    "classifier.add(Convolution2D(64, (9, 9), input_shape=(50, 50, 3),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(4,4)))\n",
    "#2nd Conv layer\n",
    "classifier.add(Convolution2D(32, (3, 3),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "                                                 target_size = (50, 50),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "                                            target_size = (50, 50),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "#steps_per_epoch = number of images in training set / batch size (which is 55839/32)\n",
    "#validation_steps = number of images in test set / batch size (which is 18739/32)\n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=(47858+109248)/32,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=(15756+39748)/32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n",
      "Found 55504 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "4910/4909 [==============================] - 568s 116ms/step - loss: 0.3808 - accuracy: 0.8364 - val_loss: 1.0451 - val_accuracy: 0.7161\n",
      "Epoch 2/15\n",
      "4910/4909 [==============================] - 1015s 207ms/step - loss: 0.3396 - accuracy: 0.8572 - val_loss: 2.1488 - val_accuracy: 0.7161\n",
      "Epoch 3/15\n",
      "4910/4909 [==============================] - 814s 166ms/step - loss: 0.3299 - accuracy: 0.8612 - val_loss: 5.3675 - val_accuracy: 0.7161\n",
      "Epoch 4/15\n",
      "4910/4909 [==============================] - 805s 164ms/step - loss: 0.3241 - accuracy: 0.8643 - val_loss: 1.3498 - val_accuracy: 0.7254\n",
      "Epoch 5/15\n",
      "4910/4909 [==============================] - 770s 157ms/step - loss: 0.3221 - accuracy: 0.8655 - val_loss: 1.2772 - val_accuracy: 0.4587\n",
      "Epoch 6/15\n",
      "4910/4909 [==============================] - 768s 156ms/step - loss: 0.3187 - accuracy: 0.8670 - val_loss: 1.6666 - val_accuracy: 0.7226\n",
      "Epoch 7/15\n",
      "4910/4909 [==============================] - 774s 158ms/step - loss: 0.3171 - accuracy: 0.8674 - val_loss: 0.5284 - val_accuracy: 0.7743\n",
      "Epoch 8/15\n",
      "4910/4909 [==============================] - 776s 158ms/step - loss: 0.3136 - accuracy: 0.8693 - val_loss: 1.5524 - val_accuracy: 0.7195\n",
      "Epoch 9/15\n",
      "4910/4909 [==============================] - 789s 161ms/step - loss: 0.3114 - accuracy: 0.8685 - val_loss: 0.9923 - val_accuracy: 0.7587\n",
      "Epoch 10/15\n",
      "4910/4909 [==============================] - 847s 173ms/step - loss: 0.3101 - accuracy: 0.8705 - val_loss: 1.6239 - val_accuracy: 0.7315\n",
      "Epoch 11/15\n",
      "4910/4909 [==============================] - 1269s 258ms/step - loss: 0.3072 - accuracy: 0.8715 - val_loss: 0.9467 - val_accuracy: 0.7511\n",
      "Epoch 12/15\n",
      "4910/4909 [==============================] - 1246s 254ms/step - loss: 0.3057 - accuracy: 0.8721 - val_loss: 3.8148 - val_accuracy: 0.7161 \n",
      "Epoch 13/15\n",
      "4910/4909 [==============================] - 1591s 324ms/step - loss: 0.3050 - accuracy: 0.8723 - val_loss: 4.1673 - val_accuracy: 0.3067\n",
      "Epoch 14/15\n",
      "4910/4909 [==============================] - 1962s 400ms/step - loss: 0.3034 - accuracy: 0.8730 - val_loss: 1.2275 - val_accuracy: 0.7384\n",
      "Epoch 15/15\n",
      "4910/4909 [==============================] - 1520s 310ms/step - loss: 0.3041 - accuracy: 0.8730 - val_loss: 0.8280 - val_accuracy: 0.7227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b1b1c4448>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequencing 8 3CL+4AL+BN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "classifier = Sequential()\n",
    "#1st Conv layer\n",
    "classifier.add(Convolution2D(128, (2, 2), input_shape=(50, 50, 3),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#2nd Conv layer\n",
    "classifier.add(Convolution2D(64, (1, 1),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(1,1)))\n",
    "#3rd Conv layer\n",
    "classifier.add(Convolution2D(32, (1, 1),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(1,1)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "                                                 target_size = (50, 50),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "                                            target_size = (50, 50),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "#steps_per_epoch = number of images in training set / batch size (which is 55839/32)\n",
    "#validation_steps = number of images in test set / batch size (which is 18739/32)\n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=(47858+109248)/32,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=(15756+39748)/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157106 images belonging to 2 classes.\n",
      "Found 55504 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "4910/4909 [==============================] - 948s 193ms/step - loss: 0.4373 - accuracy: 0.8065 - val_loss: 0.4450 - val_accuracy: 0.8049\n",
      "Epoch 2/15\n",
      "4910/4909 [==============================] - 878s 179ms/step - loss: 0.3803 - accuracy: 0.8371 - val_loss: 0.4569 - val_accuracy: 0.7954\n",
      "Epoch 3/15\n",
      "4910/4909 [==============================] - 768s 157ms/step - loss: 0.3693 - accuracy: 0.8412 - val_loss: 0.4532 - val_accuracy: 0.7904\n",
      "Epoch 4/15\n",
      "4910/4909 [==============================] - 780s 159ms/step - loss: 0.3632 - accuracy: 0.8451 - val_loss: 0.4171 - val_accuracy: 0.8163\n",
      "Epoch 5/15\n",
      "4910/4909 [==============================] - 784s 160ms/step - loss: 0.3570 - accuracy: 0.8477 - val_loss: 0.4040 - val_accuracy: 0.8192\n",
      "Epoch 6/15\n",
      "4910/4909 [==============================] - 790s 161ms/step - loss: 0.3512 - accuracy: 0.8495 - val_loss: 0.3718 - val_accuracy: 0.8364\n",
      "Epoch 7/15\n",
      "4910/4909 [==============================] - 781s 159ms/step - loss: 0.3461 - accuracy: 0.8534 - val_loss: 0.4285 - val_accuracy: 0.8015\n",
      "Epoch 8/15\n",
      "4910/4909 [==============================] - 789s 161ms/step - loss: 0.3425 - accuracy: 0.8544 - val_loss: 0.3820 - val_accuracy: 0.8338\n",
      "Epoch 9/15\n",
      "4910/4909 [==============================] - 792s 161ms/step - loss: 0.3372 - accuracy: 0.8574 - val_loss: 0.4087 - val_accuracy: 0.8164\n",
      "Epoch 10/15\n",
      "4910/4909 [==============================] - 799s 163ms/step - loss: 0.3317 - accuracy: 0.8591 - val_loss: 0.4739 - val_accuracy: 0.7900\n",
      "Epoch 11/15\n",
      "4910/4909 [==============================] - 796s 162ms/step - loss: 0.3303 - accuracy: 0.8610 - val_loss: 0.4180 - val_accuracy: 0.8203\n",
      "Epoch 12/15\n",
      "4910/4909 [==============================] - 790s 161ms/step - loss: 0.3291 - accuracy: 0.8602 - val_loss: 0.4578 - val_accuracy: 0.7936\n",
      "Epoch 13/15\n",
      "4910/4909 [==============================] - 793s 161ms/step - loss: 0.3258 - accuracy: 0.8626 - val_loss: 0.4499 - val_accuracy: 0.7958\n",
      "Epoch 14/15\n",
      "4910/4909 [==============================] - 783s 160ms/step - loss: 0.3235 - accuracy: 0.8633 - val_loss: 0.4693 - val_accuracy: 0.7976\n",
      "Epoch 15/15\n",
      "4910/4909 [==============================] - 769s 157ms/step - loss: 0.3238 - accuracy: 0.8626 - val_loss: 0.5117 - val_accuracy: 0.7965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2540905e288>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sequencing 13 4CL+5AL\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "classifier = Sequential()\n",
    "#1st Conv layer\n",
    "classifier.add(Convolution2D(64, (3, 3), input_shape=(50, 50, 3),strides=(2,2), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#2nd Conv layer\n",
    "classifier.add(Convolution2D(32, (2, 2),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#3rd Conv layer\n",
    "classifier.add(Convolution2D(32, (1, 1),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#4th Conv layer\n",
    "classifier.add(Convolution2D(16, (1, 1),strides=(1,1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\training_set',\n",
    "                                                 target_size = (50, 50),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\KIIT\\\\Desktop\\\\RESEARCH\\\\IDC\\\\split_dataset\\\\test_set',\n",
    "                                            target_size = (50, 50),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "#steps_per_epoch = number of images in training set / batch size (which is 55839/32)\n",
    "#validation_steps = number of images in test set / batch size (which is 18739/32)\n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=(47858+109248)/32,\n",
    "        epochs=15,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=(15756+39748)/32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
